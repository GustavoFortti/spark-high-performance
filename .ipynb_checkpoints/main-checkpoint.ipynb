{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b69421d",
   "metadata": {},
   "source": [
    "# Spark high perfomance\n",
    "\n",
    "    - Configuração do cluster\n",
    "    - Analise de jobs\n",
    "    - otimização de join\n",
    "    - Fair Scheduling\n",
    "    - Serialization\n",
    "    - Garbage Colector"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "984ee1b1",
   "metadata": {},
   "source": [
    "## 1. Configuração do cluster\n",
    "        \n",
    "    --num-executors= \"numero de cores por nó\"\n",
    "    --executor-cores= \"total de cores por nó\n",
    "    --executor-memory= \"total de memoria por nó\"\n",
    "    \n",
    "    - Taxa de transferência do HDFS: o cliente HDFS tem problemas com toneladas de threads simultâneos. Observou-se que o HDFS atinge a taxa de transferência total de gravação com ~5 tarefas por executor. Portanto, é bom manter o número de núcleos por executor abaixo desse número.\n",
    "\n",
    "\n",
    "### - Spark Architecture\n",
    "\n",
    "<img src=\"Spark-cluster-computing-master-slave-architecture.png\" width=\"700\" height=\"900\">\n",
    "\n",
    "### - Worker\n",
    "  \n",
    "<img src=\"1_fbAp1O2_d9pH0dCcvgfqrA.jpeg\" width=\"700\" height=\"900\">\n",
    "\n",
    "### - Um executor por nó\n",
    "<img src=\"1_OsiBkBLQi-Qxb9TTxcb0FA.jpeg\" width=\"700\" height=\"900\">\n",
    "\n",
    "    - 1 executor com 15 núcleos significa que você terá 1 JVM que pode executar no máximo 15 tarefas.\n",
    "    - Taxa de transferência do HDFS será prejudicada e resultará alto tempo GC.\n",
    "    - Se uma das tarefas nesses núcleos executar OOM ou travar de maneira incorreta, até 15 tarefas precisarão ser reprocessadas.\n",
    "   \n",
    "\n",
    "### - Um executor por core\n",
    "<img src=\"1_fP06qHvupflNshcUg6jg7w.jpeg\" width=\"700\" height=\"900\">\n",
    "\n",
    "    - 16 executor com 1 CORE significa que você terá 16 JVM e cada JVM pode executar uma tarefa.\n",
    "    - variáveis ​​compartilhadas/em cache, como variáveis ​​de transmissão e acumuladores, serão replicadas em cada núcleo dos nós, que é 15 vezes.\n",
    "    - Pouca memoria por executor (1/16), pode ocorrer OOM. \n",
    "    - Os executores normalmente não compartilham memória entre si. Portanto, se um executor não estiver usando tanta memória quanto outro, a memória não poderá ser fornecida ao executor com maiores necessidades de memória. Ou seja, a alocação de memória é menos eficiente. A menos que spark.memory.offHeap.enabled seja definido como true (é definido como false padrão).\n",
    "\n",
    "### - Cinco executores com 3 cores ou três executores com 5 cores (Equilíbrio)\n",
    "<img src=\"1_5oy8I6Jwj1QPMF3XKdAiaA.jpeg\" width=\"700\" height=\"900\">\n",
    "\n",
    "    - Com base nas recomendações mencionadas acima, vamos atribuir 5 núcleos por executores --executor-cores = 5(para uma boa taxa de transferência do HDFS)\n",
    "    - Deixe 1 núcleo por nó para daemons Hadoop/Yarn => Número de núcleos disponíveis por nó = 16-1 = 15\n",
    "    - Portanto, Total disponível de núcleos no cluster = 15 x 10 = 150\n",
    "    - Number of available executors = (total cores/num-cores-per-executor) = 150/5 = 30\n",
    "    - Deixando 1 executor para ApplicationManager => --num-executors= 29\n",
    "    - Número de executores por nó = 30/10 = 3\n",
    "    - Memória por executor = 64 GB/3 = 21 GB\n",
    "    - Contando a sobrecarga de heap = 10% de 21 GB = 3 GB. Então, real --executor-memory= 21 - 3 = 18 GB\n",
    "\n",
    "\n",
    "#### http://spark-configuration.luminousmen.com/\n",
    "\n",
    "   \n",
    "```\n",
    "spark.default.parallelism\t725\n",
    "spark.executor.memory\t18g\n",
    "spark.executor.instances\t29\n",
    "spark.driver.cores\t5\n",
    "spark.executor.cores\t5\n",
    "spark.driver.memory\t18g\n",
    "spark.driver.maxResultSize\t18g\n",
    "spark.driver.memoryOverhead\t1843m\n",
    "spark.executor.memoryOverhead\t1843m\n",
    "spark.dynamicAllocation.enabled\tfalse\n",
    "spark.sql.adaptive.enabled\ttrue\n",
    "\n",
    "spark.memory.fraction\t0.8\n",
    "spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures\t5\n",
    "spark.rdd.compress\ttrue\n",
    "spark.shuffle.compress\ttrue\n",
    "spark.shuffle.spill.compress\ttrue\n",
    "spark.serializer\torg.apache.spark.serializer.KryoSerializer\n",
    "spark.executor.extraJavaOptions\t-XX:+UseG1GC -XX:+G1SummarizeConcMark\n",
    "spark.driver.extraJavaOptions\t-XX:+UseG1GC -XX:+G1SummarizeConcMark\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4baca36a",
   "metadata": {},
   "source": [
    "## Analise de jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dced7a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/skewed-data-in-spark-add-salt-to-compensate-16d44404088b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4de1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, date\n",
    "import pandas as pd\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import spark_partition_id, asc, desc\n",
    "from pyspark.sql.functions  import spark_partition_id\n",
    "from pyspark.serializers import PickleSerializer, AutoBatchedSerializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64d26607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+----+----------+-------------------+\n",
      "|  a|  b|   c|         d|                  e|\n",
      "+---+---+----+----------+-------------------+\n",
      "|  1|4.0|GFG1|2000-08-01|2000-08-01 12:00:00|\n",
      "|  2|8.0|GFG2|2000-06-02|2000-06-02 12:00:00|\n",
      "|  4|5.0|GFG3|2000-05-03|2000-05-03 12:00:00|\n",
      "+---+---+----+----------+-------------------+\n",
      "\n",
      "root\n",
      " |-- a: long (nullable = true)\n",
      " |-- b: double (nullable = true)\n",
      " |-- c: string (nullable = true)\n",
      " |-- d: date (nullable = true)\n",
      " |-- e: timestamp (nullable = true)\n",
      "\n",
      "Numero de partições: 8\n",
      "\n",
      "Numero de linhas por partição\n",
      "+-----------+-----+\n",
      "|partitionId|count|\n",
      "+-----------+-----+\n",
      "|          5|    1|\n",
      "|          7|    1|\n",
      "|          2|    1|\n",
      "+-----------+-----+\n",
      "\n",
      "Tamanho aproximado do dataframe: 2.8 MB\n",
      "Tamanho aproximado de cada partição: 0.35 MB\n",
      "\n",
      "spark ui ->\n",
      "http://192.168.0.15:4040\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame([\n",
    "    Row(a=1, b=4., c='GFG1', d=date(2000, 8, 1),\n",
    "        e=datetime(2000, 8, 1, 12, 0)),\n",
    "   \n",
    "    Row(a=2, b=8., c='GFG2', d=date(2000, 6, 2),\n",
    "        e=datetime(2000, 6, 2, 12, 0)),\n",
    "   \n",
    "    Row(a=4, b=5., c='GFG3', d=date(2000, 5, 3),\n",
    "        e=datetime(2000, 5, 3, 12, 0))\n",
    "])\n",
    " \n",
    "# show table\n",
    "df.show()\n",
    " \n",
    "# show schema\n",
    "df.printSchema()\n",
    "\n",
    "# numero de partioções\n",
    "n_partitions = df.rdd.getNumPartitions()\n",
    "print(f'Numero de partições: {n_partitions}\\n')\n",
    "\n",
    "print('Numero de linhas por partição')\n",
    "df.withColumn(\"partitionId\", spark_partition_id()).groupBy(\"partitionId\").count().show()\n",
    "\n",
    "spark.sparkContext.getConf().getAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2665ec05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.serializer org.apache.spark.serializer.KryoSerializer\n",
    "# http://spark-configuration.luminousmen.com/\n",
    "# https://spoddutur.github.io/spark-notes/distribution_of_executors_cores_and_memory_for_spark_application.html\n",
    "# https://www.codetd.com/pt/article/10830437\n",
    "# https://databricks.com/session_na20/fine-tuning-and-enhancing-performance-of-apache-spark-jobs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
